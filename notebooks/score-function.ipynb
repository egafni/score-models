{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing I need to wrap my head around\n",
    "is what the score function is\n",
    "and how we estimate it from data.\n",
    "I will use the venerable Gaussian to anchor my understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of the score function\n",
    "is the derivative of the log density of a probability distribution\n",
    "w.r.t. the support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as np, grad\n",
    "from jax.scipy.stats import norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, 1000)\n",
    "y = norm.logpdf(x, loc=0, scale=1)\n",
    "\n",
    "model_score = grad(norm.logpdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that at the top of the Gaussian,\n",
    "the gradient should be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the tails, the gradient should be of higher magnitude\n",
    "than at the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score(-3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the score function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we have data\n",
    "but don't know the parameters of the true data-generating density?\n",
    "In this case, we need to estimate the score function,\n",
    "which means estimating the parameters of the model.\n",
    "To do this, I will lean on work by Aapo Hyvärinen from 2005 in JMLR.\n",
    "In this work, Hyvärinen proposes \n",
    "to estimate the parameters of the data-generating density\n",
    "\n",
    "> by minimizing the expected squared distance between the model score function\n",
    "> $\\psi(.;\\theta)$ and the data score function $\\psi_x(.)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This squared distance is defined as the function $J(\\theta)$,\n",
    "where $\\theta$ are the parameters of the data-generating model:\n",
    "\n",
    "> $J(\\theta) = \n",
    "\n",
    "\n",
    "TBD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random \n",
    "\n",
    "key = random.PRNGKey(44)\n",
    "\n",
    "true_mu = 3.0\n",
    "true_sigma = 1.0\n",
    "data = random.normal(key, shape=(100,)) * true_sigma + true_mu\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial \n",
    "from jax import vmap \n",
    "\n",
    "score_data = grad(partial(norm.logpdf, loc=true_mu, scale=true_sigma))\n",
    "\n",
    "true_score_data = vmap(score_data)(data)\n",
    "true_score_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1, k2, k3 = random.split(key, 3)\n",
    "mu = random.normal(k1)\n",
    "log_sigma = random.normal(k2)\n",
    "\n",
    "params_init = (mu, log_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, obs_data):\n",
    "    mu_est, log_sigma_est = params\n",
    "    sigma_est = np.exp(log_sigma_est)\n",
    "    model_score_fn = grad(partial(norm.logpdf, loc=mu_est, scale=sigma_est))\n",
    "    model_score_ffn = grad(model_score_fn)\n",
    "\n",
    "    term1 = vmap(model_score_ffn)(obs_data)\n",
    "    term2 = 0.5 * vmap(model_score_fn)(obs_data) ** 2\n",
    "\n",
    "    inner_term = term1 + term2\n",
    "\n",
    "    return np.mean(inner_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(params_init, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import value_and_grad\n",
    "dloss = value_and_grad(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "\n",
    "mu, log_sigma = params_init\n",
    "losses = []\n",
    "for i in range(1200):\n",
    "    loss_val, (dmu, dsigma) = dloss((mu, log_sigma), data)\n",
    "    mu -= dmu * 0.1\n",
    "    log_sigma -= dsigma * 0.1\n",
    "    losses.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, np.exp(log_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96a062a7e1adbb829192b5a56a463e7bc3d2201a3b05feadd05a7a64f9805fbb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
