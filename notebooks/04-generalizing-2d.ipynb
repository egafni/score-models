{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizing to 2D and beyond\n",
    "\n",
    "In this notebook, I want to show how we can generalize from 1D to 2D and beyond.\n",
    "To do that, I will use a mixture 2D Gaussian as an anchoring example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random, numpy as np, vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we generate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score_models.utils import generate_mixture_2d\n",
    "\n",
    "key = random.PRNGKey(42)\n",
    "data, k3 = generate_mixture_2d(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data just to make sure we know what it's all about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.scatter(data[:, 0], data[:, 1], alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train a score model for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of a 2D dataset is the gradient w.r.t. the inputs.\n",
    "Because the data are multi-dimensional,\n",
    "our gradients are necessarily equally dimensioned;\n",
    "they would be esssentially partial derivatives w.r.t. the input.\n",
    "Specifically, the score function maps $\\mathbb{R}^d \\rightarrow \\mathbb{R}^d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score_models.models import nn_model\n",
    "from score_models.losses import score_matching_loss\n",
    "from functools import partial\n",
    "from jaxopt import GradientDescent\n",
    "\n",
    "init_fun, nn_score_func = nn_model(output_dim=2)\n",
    "k4, k5 = random.split(k2)\n",
    "_, params_init = init_fun(k4, input_shape=(None, 2))\n",
    "\n",
    "# Test-drive forward pass\n",
    "out_test = vmap(partial(nn_score_func, params_init))(data)\n",
    "out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging purposes\n",
    "out_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to write the score matching loss.\n",
    "The score matching loss is the sum over all dimensions\n",
    "of the mean over all samples,\n",
    "as given by equation 6 in the JMLR paper (2005) by Aapo Hyv√§rinen.\n",
    "In earlier experiments, I also observed exploding weights leading to NaN values,\n",
    "so I will be applying weight L2 regularization to prevent that from happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score_models.losses import score_matching_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit \n",
    "myloss = jit(partial(score_matching_loss, score_func=nn_score_func))\n",
    "solver = GradientDescent(fun=myloss, maxiter=10000)\n",
    "result = solver.run(params_init, batch=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we sample with Langevin Dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score_models.sampler import langevin_dynamics\n",
    "\n",
    "\n",
    "# sample_shape = (1, 2)\n",
    "starter_xs = random.multivariate_normal(k5, mean=np.array([2.5, -2.5]), cov=np.eye(2)*3, shape=(4000,)) \n",
    "epsilon = 5e-3\n",
    "starting_states, final_states, chain_samples = langevin_dynamics(\n",
    "    n_chains=4000, \n",
    "    n_samples=1000, \n",
    "    key=key, \n",
    "    epsilon=epsilon, \n",
    "    score_func=nn_score_func, \n",
    "    params=result.params, \n",
    "    init_scale=10, \n",
    "    starter_xs=starter_xs,\n",
    "    # sample_shape=sample_shape,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    x, y = np.sort(data), np.arange(1, len(data) + 1) / len(data)\n",
    "    return x, y\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(data[:, 0], data[:, 1], alpha=0.1, label=\"data\")\n",
    "plt.scatter(starting_states[:, 0], starting_states[:, 1], alpha=0.1, label=\"starting samples\")\n",
    "plt.scatter(final_states[:, 0], final_states[:, 1], alpha=0.1, label=\"final samples\")\n",
    "plt.xlim(-4, 8)\n",
    "plt.ylim(-8, 4)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celluloid import Camera\n",
    "from tqdm.autonotebook import tqdm \n",
    "\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "\n",
    "for timepoint in tqdm(chain_samples.swapaxes(0, 1)):\n",
    "    plt.xlim(-4, 8)\n",
    "    plt.ylim(-8, 4)\n",
    "    plt.scatter(*timepoint.T, color=\"blue\", alpha=0.1)\n",
    "    camera.snap()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = camera.animate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "# display_html(animation)\n",
    "animation.save(\"sampling2.mp4\", dpi=300, fps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, it's powerful to just \"see\" what's happening amongst the chain samples!\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96a062a7e1adbb829192b5a56a463e7bc3d2201a3b05feadd05a7a64f9805fbb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
