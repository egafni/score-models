{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test np.where with vmap\n",
    "import jax.numpy as np\n",
    "from jax import random\n",
    "from jax.scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import vmap\n",
    "\n",
    "\n",
    "mus = np.array([80, 120])\n",
    "sigmas = np.array([10, 20])\n",
    "\n",
    "x = np.linspace(0, 300, 5000)\n",
    "xs = np.vstack([x, x])\n",
    "y1, y2 = vmap(norm.pdf)(xs, mus, sigmas)\n",
    "\n",
    "ys = np.vstack([y1, y2])\n",
    "\n",
    "# I want to find the x-values at which the heights of the two distributions\n",
    "# are 13.5% of the maximum height. (This is a magic number often used in chromatography.)\n",
    "\n",
    "\n",
    "# The most obvious solution is to use the following code:\n",
    "def values_at_frac_max(xs, ys, fraction: float = 0.135):\n",
    "    min_x = None\n",
    "    for x, y in zip(xs, ys):\n",
    "        if y >= fraction * ys.max():\n",
    "            min_x = x\n",
    "            break\n",
    "\n",
    "    max_x = None\n",
    "    for x, y in zip(xs[::-1], ys[::-1]):\n",
    "        if y >= fraction * ys.max():\n",
    "            max_x = x\n",
    "            break\n",
    "    return min_x, max_x\n",
    "\n",
    "\n",
    "values_at_frac_max(x, y2, fraction=0.135)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_at_frac_max(xs, ys, fraction: float = 0.135):\n",
    "    # The naive way:\n",
    "    max_height = np.max(ys)\n",
    "    idxs = np.where(ys >= max_height * fraction)[0]\n",
    "    return xs[idxs.min()], xs[idxs.max()]\n",
    "\n",
    "\n",
    "values_at_frac_max(xs, y1, 0.135), values_at_frac_max(xs, y2, 0.135)\n",
    "\n",
    "\n",
    "# But this doesn't work:\n",
    "# vmap(values_at_frac_max)(xs, ys)\n",
    "\n",
    "\n",
    "# We get a ConcretizationTypeError, which is because `np.where` returns something that is of variable shape.\n",
    "# However, since in this case we need just the minimum and maximum values, we can do something else.\n",
    "def values_at_frac_max(xs, ys, fraction: float = 0.135):\n",
    "    # The naive way:\n",
    "    max_height = np.max(ys)\n",
    "    idxs_min = np.where(ys >= max_height * fraction, size=1)[0]\n",
    "    idxs_max = np.where(ys >= max_height * fraction, size=len(xs))[0]\n",
    "    return np.array([xs[idxs_min.min()], xs[idxs_max.max()]])\n",
    "\n",
    "\n",
    "values_wanted = vmap(values_at_frac_max)(xs, ys)\n",
    "values_wanted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_at_frac_max(x, y1, 0.135), values_at_frac_max(x, y2, 0.135)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.plot(x, y1, color=\"red\", label=\"curve 1\")\n",
    "plt.plot(x, y2, color=\"blue\", label=\"curve 2\")\n",
    "plt.legend()\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y1, color=\"red\", label=\"curve 1\")\n",
    "plt.plot(x, y2, color=\"blue\", label=\"curve 2\")\n",
    "\n",
    "plt.hlines(\n",
    "    y=0.135 * y1.max(),\n",
    "    xmin=float(values_wanted[0, 0]),\n",
    "    xmax=float(values_wanted[0, 1]),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "plt.hlines(\n",
    "    y=0.135 * y2.max(),\n",
    "    xmin=float(values_wanted[1, 0]),\n",
    "    xmax=float(values_wanted[1, 1]),\n",
    "    color=\"blue\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "plt.legend()\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score_models.losses import score_matching_loss\n",
    "from score_models.models.feedforward import FeedForwardModel\n",
    "from score_models.models.gaussian import GaussianModel\n",
    "from score_models.data import make_gaussian\n",
    "from score_models.training import fit, default_optimizer, adam_optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from jax import random, numpy as np, vmap, jacfwd\n",
    "import optax\n",
    "\n",
    "data = make_gaussian()\n",
    "model = GaussianModel()\n",
    "model, history = fit(\n",
    "    model, data, score_matching_loss, optimizer=adam_optimizer(), steps=600\n",
    ")\n",
    "plt.plot(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_gaussian()\n",
    "model = FeedForwardModel()\n",
    "print(vmap(model)(data).shape, vmap(jacfwd(model))(data).shape)\n",
    "\n",
    "score_matching_loss(model_func=model, batch=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "from jax import grad, nn\n",
    "\n",
    "dloss = eqx.filter_jit(eqx.filter_grad(score_matching_loss))\n",
    "# optimizer = optax.chain(\n",
    "#     optax.clip(0.01),\n",
    "#     optax.sgd(learning_rate=5e-3),\n",
    "# )\n",
    "optimizer = optax.adabelief(learning_rate=1e-3)\n",
    "# model = GaussianModel()\n",
    "model = eqx.nn.Sequential(\n",
    "    [\n",
    "        eqx.nn.Linear(in_features=1, out_features=1024, key=random.PRNGKey(45)),\n",
    "        nn.relu(),\n",
    "        eqx.nn.Linear(in_features=1024, out_features=1, key=random.PRNGKey(39)),\n",
    "    ]\n",
    ")\n",
    "opt_state = optimizer.init(model)\n",
    "# print(score_matching_loss(model_func=model, batch=data))\n",
    "# model = eqx.nn.MLP(\n",
    "#             in_size=1,\n",
    "#             out_size=1,\n",
    "#             width_size=1024,\n",
    "#             depth=1,\n",
    "#             key=random.PRNGKey(45),\n",
    "#         )\n",
    "\n",
    "# opt_state = optimizer.init(model)\n",
    "# grads = dloss(model, data)\n",
    "# updates, opt_state = optimizer.update(grads, opt_state)\n",
    "# model = eqx.apply_updates(model, updates)\n",
    "# print(score_matching_loss(model_func=model, batch=data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(updates.submodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates.mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "grads.mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_gaussian()\n",
    "model = GaussianModel()\n",
    "print(vmap(model)(data).shape, vmap(jacfwd(model))(data).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "import equinox as eqx\n",
    "from jax.example_libraries import stax\n",
    "from jax import random, nn\n",
    "\n",
    "optimizer = optax.adabelief(learning_rate=1e-3)\n",
    "# model = GaussianModel()\n",
    "model = eqx.nn.Sequential(\n",
    "    [\n",
    "        eqx.nn.Linear(in_features=1, out_features=1024, key=random.PRNGKey(45)),\n",
    "        nn.relu,  # no problem when commented out\n",
    "        eqx.nn.Linear(in_features=1024, out_features=1, key=random.PRNGKey(39)),\n",
    "    ]\n",
    ")\n",
    "opt_state = optimizer.init(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "499aa38474d161e044ebb3be9240784e1719d4331ad512ef6546dcd230708004"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('score-models')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
